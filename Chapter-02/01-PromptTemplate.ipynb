{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_teddynote import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "prompt template\n"
     ]
    }
   ],
   "source": [
    "logging.langsmith(\"prompt template\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = ChatOllama(model=\"Lama3.2-korean:latest\", max_token = 1024, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['food'], input_types={}, partial_variables={}, template='{food} 의 원산지는 어디인가요?')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"{food}의 원산지는 어디인가요?\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사과 의 원산지는 어디인가요?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt.format(food=\"사과\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"{food}의 원산지는 어디인가요?\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='사과는 전 세계적으로 생산되지만, 가장 큰 생산국은 중국, 미국, 일본 등입니다. 특히 중국은 사과의 70% 이상을 생산하며, 미국과 일본은 각각 약 10%를 차지합니다.\\n\\n이 외에도 유럽, 아시아, 남미 등 다양한 지역에서도 사과가 생산되고 있습니다. 각 국가마다의 기후와 농업 환경에 따라 다양한 사과 종류가 생산됩니다.\\n\\n사과의 원산지는 다음과 같은 주요 국가들입니다:\\n\\n1. **중국**: 중국은 세계에서 가장 큰 사과 생산국 중 하나로, 특히 동북부 지역에서 많은 양을 생산합니다.\\n2. **미국**: 미국은 사과의 두 번째로 큰 생산국으로, 주로 캘리포니아, 워싱턴, 뉴욕 등에 위치한 농장에서 사과를 생산합니다.\\n3. **일본**: 일본은 사과의 세 번째로 큰 생산국으로, 특히 도쿄와 surrounding 지역에서 많은 양을 생산합니다.\\n4. **유럽**: 유럽은 다양한 사과 종류가 생산되는 지역으로, 특히 영국, 프랑스, 독일 등에 위치한 농장에서 사과를 생산합니다.\\n5. **아시아**: 아시아는 다양한 사과 종류가 생산되는 지역으로, 특히 한국, 일본, 중국 등에 위치한 농장에서 사과를 생산합니다.\\n6. **남미**: 남미는 사과의 주요 생산국 중 하나로, 특히 브라질, 아르헨티나, 칠레 등에 위치한 농장에서 사과를 생산합니다.\\n\\n이 외에도 다양한 지역에서도 사과가 생산되고 있으며, 각 국가마다의 특성과 기후에 따라 다양한 사과 종류가 생산됩니다.', additional_kwargs={}, response_metadata={'model': 'Lama3.2-korean:latest', 'created_at': '2024-10-24T11:25:40.942166Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 63794957375, 'load_duration': 10313073625, 'prompt_eval_count': 74, 'prompt_eval_duration': 1212274000, 'eval_count': 370, 'eval_duration': 52078254000}, id='run-77200200-bc61-4ec8-a801-38a20f1d629e-0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Empty request\"}')\n"
     ]
    }
   ],
   "source": [
    "chain.invoke(\"사과\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사과는 전 세계적으로 생산되지만, 가장 큰 생산국은 중국, 미국, 일본 등입니다. 특히 중국은 사과의 70% 이상을 생산하며, 미국과 일본은 각각 약 10%를 차지합니다.\\n\\n이 외에도 유럽, 아시아, 남미 등 다양한 지역에서도 사과가 생산되고 있습니다. 각 국가마다의 기후와 농업 환경에 따라 다양한 사과 종류가 생산됩니다.\\n\\n사과의 원산지는 다음과 같은 주요 국가들입니다:\\n\\n1. **중국**: 중국은 세계에서 가장 큰 사과 생산국 중 하나로, 특히 동북부 지역에서 많은 양을 생산합니다.\\n2. **미국**: 미국은 사과의 두 번째로 큰 생산국으로, 주로 캘리포니아, 워싱턴, 뉴욕 등에 위치한 농장에서 사과를 생산합니다.\\n3. **일본**: 일본은 사과의 세 번째로 큰 생산국으로, 특히 도쿄와 surrounding 지역에서 많은 양을 생산합니다.\\n4. **유럽**: 유럽은 다양한 사과 종류가 생산되는 지역으로, 특히 영국, 프랑스, 독일 등에 위치한 농장에서 사과를 생산합니다.\\n5. **아시아**: 아시아는 다양한 사과 종류가 생산되는 지역으로, 특히 한국, 일본, 중국 등에 위치한 농장에서 사과를 생산합니다.\\n6. **남미**: 남미는 사과의 주요 생산국 중 하나로, 특히 브라질, 아르헨티나, 칠레 등에 위치한 농장에서 사과를 생산합니다.\\n\\n이 외에도 다양한 지역에서도 사과가 생산되고 있으며, 각 국가마다의 특성과 기후에 따라 다양한 사과 종류가 생산됩니다.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"사과\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 방법 2. PromptTemplate 객체 생성과 동시에 prompt 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"{food}의 수도는 어디인가요?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['food'], input_types={}, partial_variables={}, template='{food}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['food1'], input_types={}, partial_variables={'food2': '고구마'}, template='{food1}와 {food2}의 원산지는 각각 무엇인가요?')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"{food1}와 {food2}의 원산지는 각각 무엇인가요?\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"food\"],\n",
    "    partial_variables={\n",
    "        \"food2\":\"고구마\"\n",
    "    }\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사과와 고구마의 원산지는 각각 무엇인가요?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(food1=\"사과\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['food1'], input_types={}, partial_variables={'food2': '바나나'}, template='{food1}와 {food2}의 원산지는 각각 무엇인가요?')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_partial = prompt.partial(food2=\"바나나\")\n",
    "prompt_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사과와 바나나의 원산지는 각각 무엇인가요?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_partial.format(food1=\"사과\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_partial | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'바나나는 아프리카에서 원산하는 과일입니다. 대한민국은 바나나를 수출하는 국가 중 하나이지만, 바나나의 원산지는 아프리카에 있습니다. 특히, 동부 아프리카와 서아프리카 지역에서 많은 바나나가 생산됩니다.\\n\\n대한민국은 바나나를 수입하고 판매하는 국가로, 다양한 수출국에서 바나나를 수입합니다.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"대한민국\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대나무와 소금의 원산지는 다음과 같습니다:\n",
      "\n",
      "1. **대나무**: 대나무는 전 세계적으로 발견되지만, 가장 많이 생산되는 지역은 아시아입니다. 특히 중국, 일본, 한국, 인도네시아 등이 주요 생산지입니다.\n",
      "2. **소금**: 소금은 전 세계적으로 발견되지만, 가장 많은 소금을 생산하는 국가들은 중동과 북아프리카입니다. 특히 이라크, 이란, 이집트, 사우디 아라비아 등이 주요 소금 생산지입니다.\n",
      "\n",
      "이 외에도 대나무와 소금의 원산지는 지역에 따라 다를 수 있으므로, 특정한 지역이나 국가에 대해 더 자세히 알고 싶다면 추가 정보를 제공해 주시면 도움이 될 것입니다.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"food1\":\"대나무\",\"food2\":\"소금\"}).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'October 25'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime  import datetime\n",
    "\n",
    "datetime.now().strftime(\"%B %d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_today():\n",
    "    return datetime.now().strftime(\"%B %d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['n'], input_types={}, partial_variables={'today': <function get_today at 0x10fc16c20>}, template='오늘 날짜는 {today}입니다. 오늘이 생일인 유명인 {n}명을 나열해 주세요. 생년월일을 표기해주세요.')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"오늘 날짜는 {today}입니다. 오늘이 생일인 유명인 {n}명을 나열해 주세요. 생년월일을 표기해주세요.\",\n",
    "    input_variables=[\"n\"],\n",
    "    partial_variables={\n",
    "        \"today\":get_today\n",
    "    },\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘 날짜는 October 25입니다. 오늘이 생일인 유명인 3명을 나열해 주세요. 생년월일을 표기해주세요.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘 날짜가 October 25일이라면, 다음과 같은 유명인들이 생일을 맞추고 있습니다:\n",
      "\n",
      "1. **Alfred Hitchcock** - 1899년 8월 13일\n",
      "2. **John Lennon** - 1940년 10월 9일\n",
      "3. **Michael Jackson** - 1958년 8월 29일\n",
      "\n",
      "이들은 모두 오늘이나 가까운 날짜에 생일을 맞추고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(3).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일로부터 template 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['fruit'], input_types={}, partial_variables={}, template='{fruit}의 색깔이 뭐야?')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import load_prompt\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = load_prompt(\"prompts/fruit_color.yaml\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'딸기의 색깔이 뭐야?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(fruit=\"딸기\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국의 수도에 대해서 알려주세요.\n",
      "수도의 특징을 다음의 양식에 맞게 정리해 주세요.\n",
      "300자 내외로 작성해 주세요.\n",
      "한글로 작성해 주세요.\n",
      "----\n",
      "# 양식\n",
      "1. 면적\n",
      "2. 인구\n",
      "3. 역사적 장소\n",
      "4. 특산품\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt2 = load_prompt(\"prompts/capital.yaml\")\n",
    "print(prompt2.format(country=\"대한민국\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt2 | ChatOpenAI(model=\"gpt-4o-mini\",temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 면적: 서울특별시는 약 605.21㎢의 면적을 가지고 있습니다.  \n",
      "2. 인구: 2023년 기준으로 서울의 인구는 약 9.7백만 명으로, 대한민국에서 가장 인구가 많은 도시입니다.  \n",
      "3. 역사적 장소: 경복궁, 창덕궁, 북촌 한옥마을 등 다양한 역사적 장소가 있으며, 조선시대의 문화유산을 잘 보존하고 있습니다.  \n",
      "4. 특산품: 서울의 특산품으로는 한방차, 전통주, 그리고 다양한 길거리 음식들이 유명합니다. 특히, 떡볶이와 순대는 서울을 대표하는 먹거리로 많은 사랑을 받고 있습니다."
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "answer = chain.stream({\"country\":\"대한민국\"})\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['tech'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tech'], input_types={}, partial_variables={}, template='{tech}의 목적은 무엇인가요?'), additional_kwargs={})])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"{tech}의 목적은 무엇인가요?\")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: 자바스크립트의 목적은 무엇인가요?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.format(tech=\"자바스크립트\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='당신은 친절한 AI 어시스턴스입니다. 당신의 이름은 박봇입니다', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='반가워요!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요. 무엇을 도와드릴까요', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='당신의 이름은 무엇입니까?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    # role, message\n",
    "   [\n",
    "       (\"system\",\"당신은 친절한 AI 어시스턴스입니다. 당신의 이름은 {name}입니다\"),\n",
    "       (\"human\",\"반가워요!\"),\n",
    "       (\"ai\",\"안녕하세요. 무엇을 도와드릴까요\"),\n",
    "       (\"human\",\"{user_input}\")\n",
    "   ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    name=\"박봇\", user_input=\"당신의 이름은 무엇입니까?\"\n",
    ")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제 이름은 박봇입니다! 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatOpenAI(model=\"gpt-4o-mini\",temperature=0).invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_template | ChatOpenAI(model=\"gpt-4o-mini\",temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제 이름은 박봇입니다! 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"name\":\"박봇\",\"user_input\":\"당신의 이름은 무엇입니까?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MessagePlaceHolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['conversation', 'word_count'], input_types={'conversation': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x125904b80>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[MessagesPlaceholder(variable_name='conversation'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], input_types={}, partial_variables={}, template='지금까지 대화를 {word_count} 단어로 요약합니다.'), additional_kwargs={})])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "        (\"human\",\"지금까지 대화를 {word_count} 단어로 요약합니다.\")\n",
    "    ]\n",
    ")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: 안녕하세요. 저는 오늘 새로 입사한 마네입니다.만나서 반갑습니다.\\nAI: 반가워요! 앞으로 잘 부탁드립니다.\\nHuman: 지금까지 대화를 5 단어로 요약합니다.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.format(\n",
    "    word_count=5,\n",
    "    conversation=[\n",
    "        (\"human\",\"안녕하세요. 저는 오늘 새로 입사한 마네입니다.만나서 반갑습니다.\"),\n",
    "        (\"ai\",\"반가워요! 앞으로 잘 부탁드립니다.\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='마네, 새로 입사, 반갑습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 60, 'total_tokens': 72, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_8bfc6a7dc2', 'finish_reason': 'stop', 'logprobs': None}, id='run-f9a68855-3753-4982-b188-3d48958a1e60-0', usage_metadata={'input_tokens': 60, 'output_tokens': 12, 'total_tokens': 72, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"word_count\" : 5,\n",
    "        \"conversation\" : [\n",
    "            (\"human\",\"안녕하세요. 저는 오늘 새로 입사한 마네입니다.만나서 반갑습니다.\"),\n",
    "            (\"ai\",\"반가워요! 앞으로 잘 부탁드립니다.\")\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
