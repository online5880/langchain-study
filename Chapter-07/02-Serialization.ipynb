{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 직렬화(Serialization)\n",
    "## 직렬화란(Serialization)?\n",
    "1. 정의\n",
    "   - 모델을 저장 가능한 형식으로 변환하는 과정\n",
    "2. 목적\n",
    "   - 모델 재사용(재훈련 없이)\n",
    "   - 모델 배포 및 공유 용이\n",
    "   - 계산 리소스 절약\n",
    "3. 장점\n",
    "   - 빠른 모델 로딩\n",
    "   - 버전 관리 가능\n",
    "   - 다양한 환경에서 사용 가능\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_lc_serializable` 클래스 메서드로 실행하여 LangChain 클래스가 직렬화 가능한지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "\n",
    "# 모델을 생성합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{tech} 에 대해서 200자 내외로 요약해줘\")\n",
    "\n",
    "# 체인을 생성합니다.\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(ChatOpenAI.is_lc_serializable())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.is_lc_serializable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 체인 직렬화\n",
    "- dumpd : 객체를 JSON 문자열로 직렬화\n",
    "- dumps : 객체를 딕셔너리로 직렬화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.load import dumpd, dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'],\n",
       " 'kwargs': {'first': {'lc': 1,\n",
       "   'type': 'constructor',\n",
       "   'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'],\n",
       "   'kwargs': {'input_variables': ['tech'],\n",
       "    'template': '{tech} 에 대해서 200자 내외로 요약해줘',\n",
       "    'template_format': 'f-string'},\n",
       "   'name': 'PromptTemplate'},\n",
       "  'last': {'lc': 1,\n",
       "   'type': 'constructor',\n",
       "   'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'],\n",
       "   'kwargs': {'model_name': 'gpt-4o-mini',\n",
       "    'temperature': 0.7,\n",
       "    'openai_api_key': {'lc': 1, 'type': 'secret', 'id': ['OPENAI_API_KEY']},\n",
       "    'max_retries': 2,\n",
       "    'n': 1},\n",
       "   'name': 'ChatOpenAI'}},\n",
       " 'name': 'RunnableSequence'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumpd_chain = dumpd(chain)\n",
    "dumpd_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"runnable\", \"RunnableSequence\"], \"kwargs\": {\"first\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"prompts\", \"prompt\", \"PromptTemplate\"], \"kwargs\": {\"input_variables\": [\"tech\"], \"template\": \"{tech} \\\\uc5d0 \\\\ub300\\\\ud574\\\\uc11c 200\\\\uc790 \\\\ub0b4\\\\uc678\\\\ub85c \\\\uc694\\\\uc57d\\\\ud574\\\\uc918\", \"template_format\": \"f-string\"}, \"name\": \"PromptTemplate\"}, \"last\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"model_name\": \"gpt-4o-mini\", \"temperature\": 0.7, \"openai_api_key\": {\"lc\": 1, \"type\": \"secret\", \"id\": [\"OPENAI_API_KEY\"]}, \"max_retries\": 2, \"n\": 1}, \"name\": \"ChatOpenAI\"}}, \"name\": \"RunnableSequence\"}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumps_chain = dumps(chain)\n",
    "dumps_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle 파일\n",
    "\n",
    "### 개요\n",
    "\n",
    "Pickle 파일은 Python 객체를 바이너리 형태로 직렬화하는 포맷입니다.\n",
    "\n",
    "### 특징\n",
    "\n",
    "1. **형식:**\n",
    "   - Python 객체를 바이너리 형태로 직렬화하는 포맷\n",
    "\n",
    "2. **특징:**\n",
    "   - Python 전용 (다른 언어와 호환 불가)\n",
    "   - 대부분의 Python 데이터 타입 지원 (리스트, 딕셔너리, 클래스 등)\n",
    "   - 객체의 상태와 구조를 그대로 보존\n",
    "\n",
    "3. **장점:**\n",
    "   - 효율적인 저장 및 전송\n",
    "   - 복잡한 객체 구조 유지\n",
    "   - 빠른 직렬화/역직렬화 속도\n",
    "\n",
    "4. **단점:**\n",
    "   - 보안 위험 (신뢰할 수 없는 데이터 역직렬화 시 주의 필요)\n",
    "   - 사람이 읽을 수 없는 바이너리 형식\n",
    "\n",
    "### 주요 용도\n",
    "\n",
    "1. 객체 캐싱\n",
    "2. 머신러닝 모델 저장\n",
    "3. 프로그램 상태 저장 및 복원\n",
    "\n",
    "### 사용법\n",
    "\n",
    "- `pickle.dump()`: 객체를 파일에 저장\n",
    "- `pickle.load()`: 파일에서 객체 로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"tech_chain.pkl\",\"wb\") as f:\n",
    "    pickle.dump(dumpd_chain,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"tech_chain.json\",\"w\") as f:\n",
    "    json.dump(dumpd_chain,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load: 저장한 모델 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저, 이전에 저장한 `pickle` 형식의 파일을 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# pickle 파일을 로드합니다.\n",
    "with open(\"tech_chain.pkl\", \"rb\") as f:\n",
    "    loaded_chain = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'],\n",
       " 'kwargs': {'first': {'lc': 1,\n",
       "   'type': 'constructor',\n",
       "   'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'],\n",
       "   'kwargs': {'input_variables': ['tech'],\n",
       "    'template': '{tech} 에 대해서 200자 내외로 요약해줘',\n",
       "    'template_format': 'f-string'},\n",
       "   'name': 'PromptTemplate'},\n",
       "  'last': {'lc': 1,\n",
       "   'type': 'constructor',\n",
       "   'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'],\n",
       "   'kwargs': {'model_name': 'gpt-4o-mini',\n",
       "    'temperature': 0.7,\n",
       "    'openai_api_key': {'lc': 1, 'type': 'secret', 'id': ['OPENAI_API_KEY']},\n",
       "    'max_retries': 2,\n",
       "    'n': 1},\n",
       "   'name': 'ChatOpenAI'}},\n",
       " 'name': 'RunnableSequence'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로드한 json 파일을 `load` 메서드를 사용하여 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dn/kpsvhr056zz6gvcnmgrkklzr0000gn/T/ipykernel_54545/1302987478.py:4: LangChainBetaWarning: The function `load` is in beta. It is actively being worked on, so the API may change.\n",
      "  chain_from_file = load(loaded_chain)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"사과는 대표적인 과일로, 전 세계에서 널리 재배되고 소비됩니다. 다양한 품종이 있으며, 달콤하고 상큼한 맛이 특징입니다. 비타민 C와 식이섬유가 풍부해 건강에 이롭고, 항산화 효과도 있습니다. 생으로 먹거나 주스, 잼, 디저트 등으로 활용되며, 전통적으로 '하나의 사과가 의사를 멀리한다'는 속담처럼 건강에 긍정적인 이미지가 있습니다.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 116, 'prompt_tokens': 21, 'total_tokens': 137, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None} id='run-baa7245f-f6ec-492c-a592-165da6a73792-0' usage_metadata={'input_tokens': 21, 'output_tokens': 116, 'total_tokens': 137, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.load import load\n",
    "\n",
    "# 체인을 로드합니다.\n",
    "chain_from_file = load(loaded_chain)\n",
    "\n",
    "# 체인을 실행합니다.\n",
    "print(chain_from_file.invoke({\"tech\": \"사과\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='사과는 대표적인 과일로, 다소 달콤하고 신맛이 나는 특성이 있습니다. 다양한 품종이 있으며, 주로 생식이나 주스, 잼 등으로 소비됩니다. 비타민 C와 식이섬유가 풍부해 건강에 도움이 되며, 항산화 작용도 있습니다. 또한, 사과는 다양한 요리에 활용되며, 세계 여러 나라에서 재배됩니다. \"하루 한 개의 사과가 의사를 멀리한다\"는 속담처럼 건강에 유익한 과일로 알려져 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 124, 'prompt_tokens': 21, 'total_tokens': 145, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None}, id='run-694ec6bd-eea1-43f1-8d68-7824670c2cf4-0', usage_metadata={'input_tokens': 21, 'output_tokens': 124, 'total_tokens': 145, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.load import load, loads\n",
    "\n",
    "load_chain = load(\n",
    "    loaded_chain, secrets_map={\"OPENAI_API_KEY\": os.environ[\"OPENAI_API_KEY\"]}\n",
    ")\n",
    "\n",
    "# 불러온 체인이 정상 동작하는지 확인합니다.\n",
    "load_chain.invoke({\"tech\": \"사과\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tech_chain.json\", \"r\") as fp:\n",
    "    loaded_from_json_chain = json.load(fp)\n",
    "    loads_chain = load(loaded_from_json_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='사과는 대표적인 과일로, 다양한 품종이 있으며, 주로 신선하게 섭취하거나 주스, 잼 등으로 가공된다. 비타민 C와 식이섬유가 풍부해 건강에 좋고, 항산화 작용으로 면역력 강화에 도움을 준다. 사과는 단맛과 신맛을 조화롭게 지니고 있어 많은 요리에 활용되며, 상징적으로는 지혜와 유혹을 나타내기도 한다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 21, 'total_tokens': 129, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None}, id='run-10eccab8-86d4-4d71-906f-40dfe5ba37a7-0', usage_metadata={'input_tokens': 21, 'output_tokens': 108, 'total_tokens': 129, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불러온 체인이 정상 동작하는지 확인합니다.\n",
    "loads_chain.invoke({\"tech\": \"사과\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
